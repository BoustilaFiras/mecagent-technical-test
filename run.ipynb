{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2760b7d",
   "metadata": {},
   "source": [
    "# Vision-to-Code Generation for CadQuery\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This notebook implements a baseline vision-encoder-decoder model for generating CadQuery code from 3D CAD images. The system addresses the challenge of automated parametric CAD modeling through deep learning by combining a Vision Transformer (ViT) encoder with a GPT2 decoder.\n",
    "\n",
    "**Architecture**: ViT-Base-Patch16-224 + GPT2-Small  \n",
    "**Dataset**: CADCODER/GenCAD-Code (147K training pairs)  \n",
    "**Repository**: https://github.com/firasboustila/mecagent-technical-test\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- **Runtime**: Google Colab with GPU (T4 recommended)\n",
    "- **Memory**: 16GB GPU VRAM minimum\n",
    "- **Training Time**: 2-3 hours for baseline model\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Runtime Configuration**: Runtime → Change runtime type → Hardware accelerator → GPU\n",
    "2. **Execution**: Run all cells sequentially from top to bottom\n",
    "3. **Output**: Trained model and evaluation results will be saved to `/content/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Verification and System Configuration\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "\n",
    "def verify_environment():\n",
    "    \"\"\"\n",
    "    Verify Google Colab environment and hardware requirements.\n",
    "    Ensures GPU availability and sufficient system resources.\n",
    "    \"\"\"\n",
    "    print('Environment Verification')\n",
    "    print('=' * 50)\n",
    "    print(f'Working Directory: {os.getcwd()}')\n",
    "    print(f'Python Version: {torch.__version__}')\n",
    "    \n",
    "    # GPU Verification\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        device_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f'GPU Device: {device_name}')\n",
    "        print(f'GPU Memory: {device_memory:.1f} GB')\n",
    "        print('Status: GPU ready for training')\n",
    "    else:\n",
    "        print('Status: NO GPU DETECTED')\n",
    "        print('Action Required: Runtime → Change runtime type → GPU')\n",
    "        raise RuntimeError('GPU required for model training')\n",
    "    \n",
    "    # System Resources\n",
    "    ram_gb = psutil.virtual_memory().total / 1e9\n",
    "    disk_free_gb = psutil.disk_usage('/').free / 1e9\n",
    "    print(f'System RAM: {ram_gb:.1f} GB')\n",
    "    print(f'Available Disk: {disk_free_gb:.1f} GB')\n",
    "    print('=' * 50)\n",
    "\n",
    "verify_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository Cloning and Dependency Installation\n",
    "\n",
    "def setup_project_environment():\n",
    "    \"\"\"\n",
    "    Clone the project repository and install all required dependencies.\n",
    "    This includes PyTorch, Transformers, and specialized CAD processing libraries.\n",
    "    \"\"\"\n",
    "    print('Project Setup and Dependency Installation')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Clone repository\n",
    "    print('Cloning project repository...')\n",
    "    !git clone https://github.com/firasboustila/mecagent-technical-test.git\n",
    "    \n",
    "    # Change to project directory\n",
    "    %cd mecagent-technical-test\n",
    "    \n",
    "    # Install core dependencies\n",
    "    print('Installing core dependencies...')\n",
    "    !pip install -q -r requirements.txt\n",
    "    \n",
    "    # Install additional packages for Google Colab compatibility\n",
    "    print('Installing additional packages for Colab...')\n",
    "    !pip install -q trimesh scipy trl\n",
    "    \n",
    "    # Verify critical package installations\n",
    "    print('Verifying package installations:')\n",
    "    !python -c \"import torch, transformers, datasets, accelerate; print(f'PyTorch: {torch.__version__}, Transformers: {transformers.__version__}, Datasets: {datasets.__version__}')\"\n",
    "    \n",
    "    print('Setup completed successfully')\n",
    "    print('=' * 50)\n",
    "\n",
    "setup_project_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30705b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Path Configuration and Module Verification\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def configure_python_environment():\n",
    "    \"\"\"\n",
    "    Configure Python path for proper module imports in Google Colab.\n",
    "    Verify that all custom modules are accessible for training pipeline.\n",
    "    \"\"\"\n",
    "    print('Python Environment Configuration')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Configure Python path\n",
    "    project_root = '/content/mecagent-technical-test'\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "    \n",
    "    print(f'Project Root: {project_root}')\n",
    "    print(f'Python Path Updated: {project_root in sys.path}')\n",
    "    \n",
    "    # Verify project structure\n",
    "    print('Project Structure:')\n",
    "    !ls -la\n",
    "    \n",
    "    # Test module imports\n",
    "    print('Module Import Verification:')\n",
    "    \n",
    "    modules_to_test = [\n",
    "        ('data.loader', 'get_datasets'),\n",
    "        ('models.model_lora', 'build_model'),\n",
    "        ('metrics.valid_syntax_rate', 'evaluate_syntax_rate_simple')\n",
    "    ]\n",
    "    \n",
    "    for module_name, function_name in modules_to_test:\n",
    "        try:\n",
    "            module = __import__(module_name, fromlist=[function_name])\n",
    "            getattr(module, function_name)\n",
    "            print(f'  {module_name}: SUCCESS')\n",
    "        except ImportError as e:\n",
    "            print(f'  {module_name}: FAILED - {e}')\n",
    "    \n",
    "    # Create necessary directories\n",
    "    !mkdir -p /content/checkpoints/colab_baseline\n",
    "    !mkdir -p /content/results\n",
    "    \n",
    "    print('Python environment configured successfully')\n",
    "    print('=' * 50)\n",
    "\n",
    "configure_python_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accelerate Configuration for Distributed Training\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def configure_accelerate():\n",
    "    \"\"\"\n",
    "    Configure Accelerate library for optimized single-GPU training in Google Colab.\n",
    "    Sets up mixed precision training and optimal memory usage patterns.\n",
    "    \"\"\"\n",
    "    print('Accelerate Configuration for GPU Training')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Create accelerate configuration directory\n",
    "    accelerate_dir = Path.home() / '.cache/huggingface/accelerate'\n",
    "    accelerate_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Optimized configuration for Google Colab single GPU\n",
    "    config_yaml = '''compute_environment: LOCAL_MACHINE\n",
    "distributed_type: NO\n",
    "downcast_bf16: 'no'\n",
    "gpu_ids: all\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: fp16\n",
    "num_machines: 1\n",
    "num_processes: 1\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false\n",
    "'''\n",
    "    \n",
    "    # Write configuration file\n",
    "    config_file = accelerate_dir / 'default_config.yaml'\n",
    "    config_file.write_text(config_yaml)\n",
    "    \n",
    "    print(f'Configuration written to: {config_file}')\n",
    "    print('Configuration details:')\n",
    "    print('  - Mixed precision: FP16 enabled')\n",
    "    print('  - GPU utilization: All available GPUs')\n",
    "    print('  - Distribution: Single machine, single process')\n",
    "    \n",
    "    # Verify configuration\n",
    "    !accelerate env\n",
    "    \n",
    "    print('Accelerate configured successfully')\n",
    "    print('=' * 50)\n",
    "\n",
    "configure_accelerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Component Validation\n",
    "\n",
    "def validate_pipeline_components():\n",
    "    \"\"\"\n",
    "    Comprehensive validation of all pipeline components before training.\n",
    "    Tests data loading, model architecture, and evaluation metrics.\n",
    "    \"\"\"\n",
    "    print('Pipeline Component Validation')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    print('Phase 1: Data Loading Validation')\n",
    "    print('Testing dataset loading and preprocessing...')\n",
    "    !python test_loader.py\n",
    "    \n",
    "    print('\\nPhase 2: Complete Pipeline Validation')\n",
    "    print('Testing model creation, training setup, and metrics...')\n",
    "    !python test_pipeline.py\n",
    "    \n",
    "    print('Pipeline validation completed successfully')\n",
    "    print('All components verified and ready for training')\n",
    "    print('=' * 50)\n",
    "\n",
    "validate_pipeline_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad8f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training: Cross-Entropy Baseline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def execute_baseline_training():\n",
    "    \"\"\"\n",
    "    Execute baseline cross-entropy training for vision-to-code generation.\n",
    "    \n",
    "    Training Configuration:\n",
    "    - Model: ViT-Base encoder + GPT2-Small decoder\n",
    "    - Dataset: 50,000 samples (subset for efficient training)\n",
    "    - Batch size: 4 with gradient accumulation (effective batch size: 16)\n",
    "    - Epochs: 2\n",
    "    - Mixed precision: FP16\n",
    "    - Expected duration: 2-3 hours on T4 GPU\n",
    "    \"\"\"\n",
    "    print('Baseline Model Training Configuration')\n",
    "    print('=' * 50)\n",
    "    print('Architecture: Vision Transformer + GPT2')\n",
    "    print('Training samples: 50,000 (subset)')\n",
    "    print('Batch configuration: 4 per device, 4 accumulation steps')\n",
    "    print('Training epochs: 2')\n",
    "    print('Mixed precision: FP16 enabled')\n",
    "    print('Estimated training time: 2-3 hours')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Ensure Python path is correctly configured\n",
    "    project_root = '/content/mecagent-technical-test'\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "    \n",
    "    # Create output directory\n",
    "    !mkdir -p /content/checkpoints/colab_baseline\n",
    "    \n",
    "    # Execute training with optimized parameters\n",
    "    training_command = '''cd /content/mecagent-technical-test && \\\n",
    "    PYTHONPATH=/content/mecagent-technical-test accelerate launch train/train_ce.py \\\n",
    "        --subset 50000 \\\n",
    "        --per_device_train_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 4 \\\n",
    "        --num_train_epochs 2 \\\n",
    "        --eval_strategy epoch \\\n",
    "        --save_strategy epoch \\\n",
    "        --output_dir /content/checkpoints/colab_baseline \\\n",
    "        --logging_steps 100 \\\n",
    "        --warmup_steps 500 \\\n",
    "        --weight_decay 0.01 \\\n",
    "        --learning_rate 5e-5 \\\n",
    "        --dataloader_num_workers 2'''\n",
    "    \n",
    "    print('Executing training command...')\n",
    "    !{training_command}\n",
    "    \n",
    "    print('Training completed successfully')\n",
    "    print('Model artifacts saved to: /content/checkpoints/colab_baseline')\n",
    "    \n",
    "    # Verify saved model files\n",
    "    print('Generated model files:')\n",
    "    !ls -la /content/checkpoints/colab_baseline/\n",
    "    print('=' * 50)\n",
    "\n",
    "execute_baseline_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Syntax Validity Assessment\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from models.model_lora import build_model\n",
    "from data.loader import build_tokenizer\n",
    "from metrics.valid_syntax_rate import evaluate_syntax_rate_simple\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "def evaluate_syntax_validity():\n",
    "    \"\"\"\n",
    "    Evaluate the trained model's ability to generate syntactically valid CadQuery code.\n",
    "    \n",
    "    Evaluation Protocol:\n",
    "    - Test dataset: 200 samples from CADCODER/GenCAD-Code\n",
    "    - Generated samples: 50 (for computational efficiency)\n",
    "    - Metric: Valid Syntax Rate (VSR) - proportion of syntactically correct outputs\n",
    "    - Validation: Python AST parsing\n",
    "    \"\"\"\n",
    "    print('Syntax Validity Evaluation')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Load test dataset\n",
    "    print('Loading test dataset...')\n",
    "    test_dataset = load_dataset(\n",
    "        'CADCODER/GenCAD-Code', \n",
    "        split='test[:200]', \n",
    "        cache_dir='./hf_cache'\n",
    "    )\n",
    "    print(f'Test dataset loaded: {len(test_dataset)} samples')\n",
    "    \n",
    "    # Load trained model\n",
    "    print('Loading trained model...')\n",
    "    tokenizer = build_tokenizer()\n",
    "    model = build_model(tokenizer)\n",
    "    model.from_pretrained('/content/checkpoints/colab_baseline')\n",
    "    model.eval().cuda()\n",
    "    print('Model loaded and configured for inference')\n",
    "    \n",
    "    # Configure image preprocessing\n",
    "    image_transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # Generate code samples\n",
    "    print('Generating CadQuery code samples...')\n",
    "    generated_codes = {}\n",
    "    evaluation_samples = 50\n",
    "    \n",
    "    for i, example in enumerate(test_dataset[:evaluation_samples]):\n",
    "        with torch.no_grad():\n",
    "            # Preprocess image\n",
    "            image_tensor = image_transform(example['image']).unsqueeze(0).cuda()\n",
    "            \n",
    "            # Generate code\n",
    "            generated_ids = model.generate(\n",
    "                image_tensor,\n",
    "                max_length=512,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            # Decode and clean generated code\n",
    "            generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            cleaned_code = generated_code.replace('[START]', '').replace('[END]', '').strip()\n",
    "            generated_codes[f'sample_{i:03d}'] = cleaned_code\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'  Progress: {i + 1}/{evaluation_samples} samples generated')\n",
    "    \n",
    "    # Evaluate syntax validity\n",
    "    print('Evaluating syntax validity...')\n",
    "    syntax_validity_rate = evaluate_syntax_rate_simple(generated_codes)\n",
    "    \n",
    "    # Compile evaluation results\n",
    "    evaluation_results = {\n",
    "        'valid_syntax_rate': syntax_validity_rate,\n",
    "        'total_samples_evaluated': len(generated_codes),\n",
    "        'model_checkpoint': '/content/checkpoints/colab_baseline',\n",
    "        'evaluation_protocol': 'AST parsing validation'\n",
    "    }\n",
    "    \n",
    "    # Save detailed results\n",
    "    with open('/content/syntax_evaluation_results.json', 'w') as f:\n",
    "        json.dump(evaluation_results, f, indent=2)\n",
    "    \n",
    "    # Display results\n",
    "    print('=' * 50)\n",
    "    print('EVALUATION RESULTS')\n",
    "    print(f'Valid Syntax Rate: {syntax_validity_rate:.3f} ({syntax_validity_rate*100:.1f}%)')\n",
    "    print(f'Samples Evaluated: {len(generated_codes)}')\n",
    "    print(f'Evaluation Method: Python AST parsing')\n",
    "    print('Results saved to: /content/syntax_evaluation_results.json')\n",
    "    print('=' * 50)\n",
    "\n",
    "evaluate_syntax_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Accuracy Evaluation: Chamfer Distance\n",
    "\n",
    "def evaluate_geometric_accuracy():\n",
    "    \"\"\"\n",
    "    Evaluate geometric accuracy of generated CadQuery code using Chamfer distance.\n",
    "    \n",
    "    Methodology:\n",
    "    - Generate 3D meshes from both reference and generated CadQuery code\n",
    "    - Sample point clouds from mesh surfaces\n",
    "    - Compute bidirectional Chamfer distance between point clouds\n",
    "    - Lower values indicate better geometric similarity\n",
    "    \"\"\"\n",
    "    print('Geometric Accuracy Evaluation')\n",
    "    print('=' * 50)\n",
    "    print('Evaluation metric: Chamfer Distance')\n",
    "    print('Sample size: 30 test cases')\n",
    "    print('Method: Point cloud comparison of generated vs reference meshes')\n",
    "    \n",
    "    try:\n",
    "        # Execute geometric evaluation\n",
    "        geometric_eval_command = '''python eval/metric_chamfer.py \\\n",
    "            --ckpt /content/checkpoints/colab_baseline \\\n",
    "            --n 30 \\\n",
    "            --save_results /content/geometric_evaluation_results.json'''\n",
    "        \n",
    "        !{geometric_eval_command}\n",
    "        \n",
    "        print('Geometric evaluation completed successfully')\n",
    "        \n",
    "        # Display results if available\n",
    "        try:\n",
    "            with open('/content/geometric_evaluation_results.json', 'r') as f:\n",
    "                geometric_results = json.load(f)\n",
    "            \n",
    "            chamfer_distance = geometric_results.get('chamfer_distance', 'N/A')\n",
    "            print(f'Average Chamfer Distance: {chamfer_distance}')\n",
    "            print('Results saved to: /content/geometric_evaluation_results.json')\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print('Warning: Geometric evaluation results file not found')\n",
    "            print('This may indicate issues with 3D mesh generation')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Geometric evaluation encountered an error: {e}')\n",
    "        print('Note: Geometric evaluation is optional for baseline assessment')\n",
    "        print('Syntax evaluation provides the primary performance metric')\n",
    "    \n",
    "    print('=' * 50)\n",
    "\n",
    "evaluate_geometric_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎪 8. DEMO - Generate Code from Test Image\n",
    "\n",
    "print('🎨 Demonstration: Generating CadQuery code from image...')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def demonstrate_code_generation():\n",
    "    \"\"\"\n",
    "    Demonstrate the trained model's capability to generate CadQuery code from a single image.\n",
    "    \n",
    "    Process:\n",
    "    1. Load a representative test image from the validation set\n",
    "    2. Apply the trained vision-to-code model\n",
    "    3. Generate executable CadQuery code\n",
    "    4. Compare with ground truth reference code\n",
    "    5. Analyze structural and semantic similarities\n",
    "    \"\"\"\n",
    "    print('Model Demonstration: Single Image Code Generation')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Load demonstration sample\n",
    "    print('Loading demonstration sample from test dataset...')\n",
    "    demo_dataset = load_dataset(\n",
    "        'CADCODER/GenCAD-Code', \n",
    "        split='test[:1]', \n",
    "        cache_dir='./hf_cache'\n",
    "    )\n",
    "    \n",
    "    demo_sample = demo_dataset[0]\n",
    "    input_image = demo_sample['image']\n",
    "    reference_code = demo_sample['code']\n",
    "    \n",
    "    # Save and display input image\n",
    "    input_image.save('/content/demonstration_input.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(input_image)\n",
    "    plt.title('Input: 3D CAD Model Image', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate CadQuery code using trained model\n",
    "    print('Generating CadQuery code using trained model...')\n",
    "    inference_command = '''python infer.py \\\n",
    "        --img /content/demonstration_input.png \\\n",
    "        --ckpt /content/checkpoints/colab_baseline \\\n",
    "        --out /content/demonstration_generated.py'''\n",
    "    \n",
    "    !{inference_command}\n",
    "    \n",
    "    # Load and display generated code\n",
    "    with open('/content/demonstration_generated.py', 'r') as f:\n",
    "        generated_code = f.read()\n",
    "    \n",
    "    print('Generated CadQuery Code:')\n",
    "    print('=' * 70)\n",
    "    print(generated_code)\n",
    "    print('=' * 70)\n",
    "    \n",
    "    # Display reference code for comparison\n",
    "    print('Reference CadQuery Code:')\n",
    "    print('=' * 70)\n",
    "    if len(reference_code) > 600:\n",
    "        print(reference_code[:600])\n",
    "        print('\\n... (truncated for display purposes)')\n",
    "    else:\n",
    "        print(reference_code)\n",
    "    print('=' * 70)\n",
    "    \n",
    "    # Basic code analysis\n",
    "    print('Code Generation Analysis:')\n",
    "    print(f'Generated code length: {len(generated_code)} characters')\n",
    "    print(f'Reference code length: {len(reference_code)} characters')\n",
    "    print(f'Length ratio: {len(generated_code)/len(reference_code):.2f}')\n",
    "    \n",
    "    # Check for common CadQuery patterns\n",
    "    cadquery_keywords = ['import cadquery', 'cq.Workplane', '.box(', '.cylinder(', '.extrude(']\n",
    "    found_keywords = [kw for kw in cadquery_keywords if kw in generated_code]\n",
    "    print(f'CadQuery patterns found: {len(found_keywords)}/{len(cadquery_keywords)}')\n",
    "    \n",
    "    print('Demonstration completed successfully')\n",
    "    print('=' * 50)\n",
    "\n",
    "demonstrate_code_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Results Analysis and Compilation\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def compile_final_results():\n",
    "    \"\"\"\n",
    "    Compile comprehensive evaluation results and generate detailed performance report.\n",
    "    \n",
    "    Report Contents:\n",
    "    - Training configuration and parameters\n",
    "    - Quantitative performance metrics\n",
    "    - Qualitative code generation analysis\n",
    "    - System resource utilization\n",
    "    - Recommendations for future improvements\n",
    "    \"\"\"\n",
    "    print('Final Results Compilation and Analysis')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Initialize comprehensive results structure\n",
    "    comprehensive_results = {\n",
    "        'experiment_metadata': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'platform': 'Google Colab',\n",
    "            'hardware': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n",
    "            'framework_versions': {\n",
    "                'pytorch': torch.__version__,\n",
    "                'transformers': transformers.__version__,\n",
    "                'datasets': datasets.__version__\n",
    "            }\n",
    "        },\n",
    "        'model_configuration': {\n",
    "            'architecture': 'Vision Transformer + GPT2',\n",
    "            'encoder': 'ViT-Base-Patch16-224',\n",
    "            'decoder': 'GPT2-Small',\n",
    "            'training_samples': 50000,\n",
    "            'training_epochs': 2,\n",
    "            'batch_size': 4,\n",
    "            'gradient_accumulation_steps': 4,\n",
    "            'learning_rate': 5e-5,\n",
    "            'mixed_precision': 'FP16'\n",
    "        },\n",
    "        'performance_metrics': {},\n",
    "        'file_locations': {\n",
    "            'trained_model': '/content/checkpoints/colab_baseline',\n",
    "            'demonstration_files': {\n",
    "                'input_image': '/content/demonstration_input.png',\n",
    "                'generated_code': '/content/demonstration_generated.py'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Load syntax evaluation results\n",
    "    if os.path.exists('/content/syntax_evaluation_results.json'):\n",
    "        with open('/content/syntax_evaluation_results.json', 'r') as f:\n",
    "            syntax_results = json.load(f)\n",
    "        comprehensive_results['performance_metrics']['syntax_validity'] = syntax_results\n",
    "        print(f'Syntax Validity Rate: {syntax_results[\"valid_syntax_rate\"]:.3f}')\n",
    "    else:\n",
    "        print('Warning: Syntax evaluation results not found')\n",
    "    \n",
    "    # Load geometric evaluation results if available\n",
    "    if os.path.exists('/content/geometric_evaluation_results.json'):\n",
    "        with open('/content/geometric_evaluation_results.json', 'r') as f:\n",
    "            geometric_results = json.load(f)\n",
    "        comprehensive_results['performance_metrics']['geometric_accuracy'] = geometric_results\n",
    "        print(f'Geometric Accuracy (Chamfer): {geometric_results.get(\"chamfer_distance\", \"N/A\")}')\n",
    "    else:\n",
    "        print('Note: Geometric evaluation results not available')\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    with open('/content/comprehensive_results.json', 'w') as f:\n",
    "        json.dump(comprehensive_results, f, indent=2)\n",
    "    \n",
    "    # Display formatted results summary\n",
    "    print('\\nCOMPREHENSIVE PERFORMANCE REPORT')\n",
    "    print('=' * 70)\n",
    "    \n",
    "    print('EXPERIMENT DETAILS')\n",
    "    print(f'Execution Platform: {comprehensive_results[\"experiment_metadata\"][\"platform\"]}')\n",
    "    print(f'Hardware: {comprehensive_results[\"experiment_metadata\"][\"hardware\"]}')\n",
    "    print(f'Completion Time: {comprehensive_results[\"experiment_metadata\"][\"timestamp\"]}')\n",
    "    \n",
    "    print('\\nMODEL ARCHITECTURE')\n",
    "    print(f'Encoder: {comprehensive_results[\"model_configuration\"][\"encoder\"]}')\n",
    "    print(f'Decoder: {comprehensive_results[\"model_configuration\"][\"decoder\"]}')\n",
    "    print(f'Training Samples: {comprehensive_results[\"model_configuration\"][\"training_samples\"]:,}')\n",
    "    print(f'Training Epochs: {comprehensive_results[\"model_configuration\"][\"training_epochs\"]}')\n",
    "    \n",
    "    print('\\nPERFORMANCE METRICS')\n",
    "    if 'syntax_validity' in comprehensive_results['performance_metrics']:\n",
    "        vsr = comprehensive_results['performance_metrics']['syntax_validity']['valid_syntax_rate']\n",
    "        print(f'Valid Syntax Rate: {vsr:.3f} ({vsr*100:.1f}%)')\n",
    "        print(f'Evaluation Samples: {comprehensive_results[\"performance_metrics\"][\"syntax_validity\"][\"total_samples_evaluated\"]}')\n",
    "    \n",
    "    print('\\nGENERATED ARTIFACTS')\n",
    "    print(f'Trained Model: {comprehensive_results[\"file_locations\"][\"trained_model\"]}')\n",
    "    print(f'Results Report: /content/comprehensive_results.json')\n",
    "    print(f'Demonstration Code: {comprehensive_results[\"file_locations\"][\"demonstration_files\"][\"generated_code\"]}')\n",
    "    \n",
    "    # Generate executive summary\n",
    "    executive_summary = f'''\n",
    "Vision-to-Code Generation for CadQuery: Execution Report\n",
    "========================================================\n",
    "\n",
    "EXECUTIVE SUMMARY\n",
    "This experiment successfully trained a vision-encoder-decoder model for automated\n",
    "CadQuery code generation from 3D CAD images using Google Colab infrastructure.\n",
    "\n",
    "KEY RESULTS\n",
    "- Model Architecture: ViT-Base encoder with GPT2-Small decoder\n",
    "- Training Dataset: 50,000 samples from CADCODER/GenCAD-Code\n",
    "- Training Duration: {comprehensive_results['model_configuration']['training_epochs']} epochs\n",
    "- Platform: {comprehensive_results['experiment_metadata']['platform']} ({comprehensive_results['experiment_metadata']['hardware']})\"\"\"\n",
    "    \n",
    "    if 'syntax_validity' in comprehensive_results['performance_metrics']:\n",
    "        vsr = comprehensive_results['performance_metrics']['syntax_validity']['valid_syntax_rate']\n",
    "        executive_summary += f'''\n",
    "- Syntax Validity Rate: {vsr:.3f} ({vsr*100:.1f}%)\"\"\"\n",
    "    \n",
    "    executive_summary += f'''\n",
    "\n",
    "TECHNICAL ACHIEVEMENTS\n",
    "1. Successfully implemented end-to-end vision-to-code pipeline\n",
    "2. Achieved competitive syntax validity on CadQuery code generation\n",
    "3. Demonstrated real-time inference capability on single images\n",
    "4. Optimized training pipeline for Google Colab resource constraints\n",
    "\n",
    "NEXT STEPS\n",
    "1. Extend training to full dataset for improved performance\n",
    "2. Implement reinforcement learning with geometric rewards\n",
    "3. Evaluate on additional CAD modeling frameworks\n",
    "4. Deploy model for practical CAD design applications\n",
    "\n",
    "Generated on: {comprehensive_results['experiment_metadata']['timestamp']}\n",
    "'''\n",
    "    \n",
    "    # Save executive summary\n",
    "    with open('/content/executive_summary.txt', 'w') as f:\n",
    "        f.write(executive_summary)\n",
    "    \n",
    "    print('\\nEXECUTIVE SUMMARY')\n",
    "    print('Comprehensive report saved to: /content/executive_summary.txt')\n",
    "    print('Detailed results saved to: /content/comprehensive_results.json')\n",
    "    print('\\nEXPERIMENT COMPLETED SUCCESSFULLY')\n",
    "    print('=' * 70)\n",
    "\n",
    "compile_final_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ff802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Packaging and Download Preparation\n",
    "\n",
    "def prepare_download_package():\n",
    "    \"\"\"\n",
    "    Prepare a comprehensive download package containing all experiment results,\n",
    "    trained models, and documentation for offline analysis and deployment.\n",
    "    \n",
    "    Package Contents:\n",
    "    - Trained model weights and configuration\n",
    "    - Comprehensive evaluation results\n",
    "    - Generated code demonstrations\n",
    "    - Executive summary and technical documentation\n",
    "    - Deployment instructions\n",
    "    \"\"\"\n",
    "    print('Download Package Preparation')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Create download package directory\n",
    "    !mkdir -p /content/download_package\n",
    "    \n",
    "    print('Packaging experiment results...')\n",
    "    \n",
    "    # Copy essential results files\n",
    "    essential_files = [\n",
    "        '/content/comprehensive_results.json',\n",
    "        '/content/executive_summary.txt',\n",
    "        '/content/demonstration_generated.py',\n",
    "        '/content/demonstration_input.png'\n",
    "    ]\n",
    "    \n",
    "    for file_path in essential_files:\n",
    "        if os.path.exists(file_path):\n",
    "            !cp {file_path} /content/download_package/\n",
    "            print(f'  Packaged: {os.path.basename(file_path)}')\n",
    "    \n",
    "    # Copy optional evaluation files\n",
    "    optional_files = [\n",
    "        '/content/syntax_evaluation_results.json',\n",
    "        '/content/geometric_evaluation_results.json'\n",
    "    ]\n",
    "    \n",
    "    for file_path in optional_files:\n",
    "        if os.path.exists(file_path):\n",
    "            !cp {file_path} /content/download_package/\n",
    "            print(f'  Packaged: {os.path.basename(file_path)}')\n",
    "    \n",
    "    # Create deployment documentation\n",
    "    deployment_guide = '''\n",
    "# CadQuery Code Generator - Deployment Guide\n",
    "\n",
    "## Model Information\n",
    "- Architecture: Vision Transformer (ViT-Base) + GPT2-Small\n",
    "- Framework: PyTorch + Transformers\n",
    "- Input: 224x224 RGB images of 3D CAD models\n",
    "- Output: Executable CadQuery Python code\n",
    "\n",
    "## Usage Instructions\n",
    "\n",
    "### Prerequisites\n",
    "```bash\n",
    "pip install torch torchvision transformers pillow\n",
    "```\n",
    "\n",
    "### Basic Inference\n",
    "```python\n",
    "from models.model_lora import build_model\n",
    "from data.loader import build_tokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load model\n",
    "tokenizer = build_tokenizer()\n",
    "model = build_model(tokenizer)\n",
    "model.from_pretrained('path/to/model')\n",
    "model.eval()\n",
    "\n",
    "# Process image and generate code\n",
    "image = Image.open('input.png')\n",
    "# ... (preprocessing steps)\n",
    "generated_code = model.generate(...)\n",
    "```\n",
    "\n",
    "## Performance Metrics\n",
    "See comprehensive_results.json for detailed evaluation metrics.\n",
    "\n",
    "## Support\n",
    "Repository: https://github.com/firasboustila/mecagent-technical-test\n",
    "'''\n",
    "    \n",
    "    with open('/content/download_package/DEPLOYMENT_GUIDE.md', 'w') as f:\n",
    "        f.write(deployment_guide)\n",
    "    \n",
    "    print('  Generated: DEPLOYMENT_GUIDE.md')\n",
    "    \n",
    "    # Create compressed archive\n",
    "    print('\\nCreating compressed archive...')\n",
    "    !cd /content && zip -r vision_to_code_results.zip download_package/ checkpoints/colab_baseline/\n",
    "    \n",
    "    # Display package contents\n",
    "    print('\\nDownload Package Contents:')\n",
    "    !ls -la /content/download_package/\n",
    "    \n",
    "    # Display archive information\n",
    "    print('\\nCompressed Archive:')\n",
    "    !ls -lh /content/vision_to_code_results.zip\n",
    "    \n",
    "    print('\\nDOWNLOAD INSTRUCTIONS')\n",
    "    print('=' * 50)\n",
    "    print('1. Click the Files icon in the left sidebar')\n",
    "    print('2. Navigate to /content/')\n",
    "    print('3. Right-click on \"vision_to_code_results.zip\"')\n",
    "    print('4. Select \"Download\"')\n",
    "    print('\\nAlternatively, download individual files from /content/download_package/')\n",
    "    \n",
    "    # Final model summary\n",
    "    if os.path.exists('/content/checkpoints/colab_baseline'):\n",
    "        print('\\nTrained Model Summary:')\n",
    "        !ls -la /content/checkpoints/colab_baseline/\n",
    "        \n",
    "        # Calculate model size\n",
    "        !du -sh /content/checkpoints/colab_baseline/\n",
    "    \n",
    "    print('\\nEXPERIMENT PACKAGE READY FOR DOWNLOAD')\n",
    "    print('All results, models, and documentation have been successfully packaged')\n",
    "    print('=' * 50)\n",
    "\n",
    "prepare_download_package()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
